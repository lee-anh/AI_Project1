#include "Agent.h"

/// @brief Agent constructor which
/// @param puzzleRoot initial state
/// @param heuristic which to use
/// @param outputFileName where to output data to
Agent::Agent(Node* puzzleRoot, int heuristic, string outputFileName) {
  root = puzzleRoot;
  current = root;
  deepestDepth = 0;
  this->heuristic = heuristic;
  this->outputFileName = outputFileName;
  sumBranchingFactor = 0;
  sumFrontierSize = 0;
  timeToSolve = 0;
  totalNumberOfNodes = 1;
  totalNumberOfParentNodes = 1;
  pq.push(root);
  reached = new ReachedTree();
}

/// @brief perform A* search, can detect if there is a solution or not
/// includes timing measurements
/// @return last node if there is a solution
Node* Agent::AStarSearch() {
  auto start = chrono::high_resolution_clock::now();
  while (!pq.empty()) {
    sumFrontierSize += pq.size();
    current = pq.top();
    pq.pop();
    if (Checker::isGoalState(current->getState())) {
      auto stop = chrono::high_resolution_clock::now();
      auto duration = duration_cast<chrono::microseconds>(stop - start);
      timeToSolve = duration.count();
      outputToLog(current, true);
      //  bool correct = Checker::isSolution(root->getState(), backtraceSolution(current));

      return current;
    }
    expand();
  }
  auto stop = chrono::high_resolution_clock::now();
  auto duration = duration_cast<chrono::microseconds>(stop - start);
  timeToSolve = duration.count();
  outputToLog(current, false);
  return NULL;
}

/// @brief getter for time to solve a problem from start to finish
/// @return
int Agent::getTimeToSolve() {
  return timeToSolve;
}

/// @brief getter for number of nodes generated by the A* search
/// @return
long Agent::getTotalNumberOfNodes() {
  return totalNumberOfNodes;
}

/// @brief getter for number of parent nodes/expanded nodes
/// @return
long Agent::getTotalNumberOfParentNodes() {
  return totalNumberOfParentNodes;
}

/// @brief getter for solution depth
/// @return
int Agent::getDeepestDepth() {
  return deepestDepth;
}

/// @brief calculates the average branching factor
/// @return
float Agent::getAverageBranchingFactor() {
  return sumBranchingFactor * 1.0 / totalNumberOfParentNodes;
}

/// @brief calculates the average frontier size
/// @return
float Agent::getAverageFrontierSize() {
  return sumFrontierSize * 1.0 / totalNumberOfParentNodes;  // I don't think this is super insightful
}

/// @brief helper to expand, adds the child node to the frontier (priority queue)
/// @param puzzle to find the child of
/// @param move which child to find
void Agent::addChild(Puzzle* puzzle, int move) {
  // don't add the node if we've seen this state before
  if (reached->isReached(puzzle->getPuzzleArray())) {
    return;
  }
  int heuristicEstimate = Heuristic::calculateHeuristic(puzzle, heuristic);
  int depth = current->getDepth() + 1;
  Node* toPush = new Node(puzzle, current, move, depth + heuristicEstimate, depth, heuristicEstimate);
  pq.push(toPush);
  if (depth > deepestDepth) {
    deepestDepth = depth;
  }
}

/// @brief expand the current node by finding and adding possible children
/// check if each possible action is applicable to the state and perform action if it is
void Agent::expand() {
  int numberOfChildren = 0;
  totalNumberOfParentNodes++;

  Puzzle* currentState = current->getState();
  int previousAction = current->getAction();
  if (currentState->canMoveDown(previousAction)) {
    Puzzle* down = currentState->moveDown();
    numberOfChildren++;
    addChild(down, 1);
  }
  if (currentState->canMoveLeft(previousAction)) {
    Puzzle* left = currentState->moveLeft();
    numberOfChildren++;
    addChild(left, 2);
  }
  if (currentState->canMoveRight(previousAction)) {
    Puzzle* right = currentState->moveRight();
    numberOfChildren++;
    addChild(right, 3);
  }
  if (currentState->canMoveUp(previousAction)) {
    Puzzle* up = currentState->moveUp();
    numberOfChildren++;
    addChild(up, 4);
  }
  sumBranchingFactor += numberOfChildren;
  totalNumberOfNodes += numberOfChildren;
}

/// @brief write solution data to log
/// @param solution the last node
/// @param solved whether or not the puzzle was solvable
void Agent::outputToLog(Node* solution, bool solved) {
  ofstream myFile;
  myFile.open(outputFileName, ios_base::app);
  myFile << timeToSolve << "\t" << getAverageBranchingFactor() << "\t"
         << getAverageFrontierSize() << "\t" << totalNumberOfNodes << "\t"
         << solution->getDepth() << "\t" << deepestDepth << "\t"
         << Checker::isSolution(root->getState(), backtraceSolution(current)) << "\t"
         << solved << endl;

  //
  myFile.close();
}

/// @brief construct the solution by recording the move and following the parent nodes up the searched state space
/// @param solution the last node
/// @return a proposed solution of how to get from inital state to goal state (reversed order)
vector<int> Agent::backtraceSolution(Node* solution) {
  vector<int> toReturn;
  Node* curr = solution;

  while (curr->getDepth() > 0) {  // if the depth is 0 then we are on the parent node and it won't have an action
    toReturn.push_back(curr->getAction());
    // keep traveling up
    curr = curr->getParentNode();
  }

  return toReturn;
}
